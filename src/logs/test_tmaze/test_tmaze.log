2025-09-12 11:22:51,564 - INFO - Starting experiment: test_tmaze
2025-09-12 11:22:51,564 - INFO - Model: drqn, Environment: tmaze
2025-09-12 11:22:51,564 - INFO - Model config: DRQNConfig(hidden_size=32, num_layers=2, learning_rate=0.001, batch_size=32, epsilon=0.2, gamma=0.98, buffer_capacity=8192, target_update_freq=10, cell_type='gru')
2025-09-12 11:22:51,564 - INFO - Environment config: TMazeConfig(name='tmaze', length=1, stochasticity=0.0, irrelevant_features=0)
2025-09-12 11:22:51,564 - INFO - Training config: TrainingConfig(num_episodes=5, eval_period=100, eval_every=5, num_rollouts=50, save_period=1000, save_every=5, log_dir='./logs', save_dir='./models', seed=42, cuda=False)
2025-09-12 11:22:51,564 - INFO - Using CPU
2025-09-12 11:22:51,566 - INFO - Created environment: TMazeEnvironment
2025-09-12 11:22:52,111 - INFO - Created agent: DRQNAgent
2025-09-12 11:22:52,111 - INFO - Starting DRQN training on T-maze
2025-09-12 11:22:52,117 - INFO - Episode 5/5, Avg Reward: 0.160, Success Rate: 0.200, Loss: N/A
2025-09-12 11:22:52,119 - INFO - Model saved to logs/test_tmaze/model_episode_5.pt
2025-09-12 11:22:52,119 - INFO - Training completed in 0.01 seconds
2025-09-12 11:22:52,119 - INFO - Evaluating agent for 50 rollouts
2025-09-12 11:22:52,223 - INFO - Evaluation Results - Avg Reward: -1.100, Success Rate: 0.000
2025-09-12 11:22:52,224 - INFO - Final model saved to logs/test_tmaze/test_tmaze_final.pt
2025-09-12 11:22:52,224 - INFO - ==================================================
2025-09-12 11:22:52,224 - INFO - EXPERIMENT SUMMARY
2025-09-12 11:22:52,224 - INFO - ==================================================
2025-09-12 11:22:52,224 - INFO - Model: drqn
2025-09-12 11:22:52,224 - INFO - Environment: tmaze
2025-09-12 11:22:52,224 - INFO - Training Episodes: 5
2025-09-12 11:22:52,224 - INFO - Final Avg Reward: -1.100
2025-09-12 11:22:52,225 - INFO - Success Rate: 0.000
2025-09-12 11:22:52,225 - INFO - Training Time: 0.01s
2025-09-12 11:22:52,225 - INFO - ==================================================
