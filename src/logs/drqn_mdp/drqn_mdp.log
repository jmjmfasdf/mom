2025-12-01 15:09:36,402 - INFO - Starting experiment: drqn_mdp
2025-12-01 15:09:36,402 - INFO - Model: drqn, Environment: mdp
2025-12-01 15:09:36,402 - INFO - Model config: DRQNConfig(hidden_size=32, num_layers=2, learning_rate=0.001, batch_size=1, epsilon=0.1, gamma=0.98, buffer_capacity=8192, target_update_freq=10, cell_type='gru')
2025-12-01 15:09:36,402 - INFO - Environment config: MDPConfig(name='mdp', s1_duration=1, s2_duration=1)
2025-12-01 15:09:36,402 - INFO - Training config: TrainingConfig(num_episodes=500, eval_period=100, eval_every=100, num_rollouts=50, save_period=1000, save_every=100, log_dir='./logs', save_dir='./models', seed=1, cuda=True)
2025-12-01 15:09:36,402 - INFO - Using CUDA
2025-12-01 15:09:36,402 - INFO - Created environment: MDPEnvironment
2025-12-01 15:09:37,074 - INFO - Created agent: DRQNAgent
2025-12-01 15:09:37,076 - INFO - Starting DRQN training on Two-Step task
2025-12-01 15:09:37,639 - INFO - Evaluating agent for 50 rollouts
2025-12-01 15:09:37,718 - INFO - Evaluation Results - Avg Reward: 0.360, Success Rate: 0.220
2025-12-01 15:09:37,718 - INFO - Episode 100/500, Eval Avg Reward: 0.360, Eval Success Rate: 0.220, Train Loss: 0.0000
2025-12-01 15:09:37,722 - INFO - Model saved to logs/drqn_mdp/model_episode_100.pt
2025-12-01 15:09:45,125 - INFO - Evaluating agent for 50 rollouts
2025-12-01 15:09:45,237 - INFO - Evaluation Results - Avg Reward: 0.660, Success Rate: 0.880
2025-12-01 15:09:45,237 - INFO - Episode 200/500, Eval Avg Reward: 0.660, Eval Success Rate: 0.880, Train Loss: 0.0363
2025-12-01 15:09:45,240 - INFO - Model saved to logs/drqn_mdp/model_episode_200.pt
2025-12-01 15:09:54,319 - INFO - Evaluating agent for 50 rollouts
2025-12-01 15:09:54,398 - INFO - Evaluation Results - Avg Reward: 0.500, Success Rate: 0.300
2025-12-01 15:09:54,398 - INFO - Episode 300/500, Eval Avg Reward: 0.500, Eval Success Rate: 0.300, Train Loss: 0.0182
2025-12-01 15:09:54,401 - INFO - Model saved to logs/drqn_mdp/model_episode_300.pt
2025-12-01 15:10:01,847 - INFO - Evaluating agent for 50 rollouts
2025-12-01 15:10:01,924 - INFO - Evaluation Results - Avg Reward: 0.480, Success Rate: 0.240
2025-12-01 15:10:01,925 - INFO - Episode 400/500, Eval Avg Reward: 0.480, Eval Success Rate: 0.240, Train Loss: 0.0010
2025-12-01 15:10:01,927 - INFO - Model saved to logs/drqn_mdp/model_episode_400.pt
2025-12-01 15:10:11,189 - INFO - Evaluating agent for 50 rollouts
2025-12-01 15:10:11,269 - INFO - Evaluation Results - Avg Reward: 0.540, Success Rate: 0.220
2025-12-01 15:10:11,269 - INFO - Episode 500/500, Eval Avg Reward: 0.540, Eval Success Rate: 0.220, Train Loss: 0.0001
2025-12-01 15:10:11,272 - INFO - Model saved to logs/drqn_mdp/model_episode_500.pt
2025-12-01 15:10:11,277 - INFO - Training trajectories and activations saved to logs/drqn_mdp/train_episodes_mdp_1764569411.npz
2025-12-01 15:10:11,278 - INFO - Training completed in 34.20 seconds
2025-12-01 15:10:11,278 - INFO - Evaluating agent for 50 rollouts
2025-12-01 15:10:11,358 - INFO - Evaluation Results - Avg Reward: 0.460, Success Rate: 0.280
2025-12-01 15:10:11,360 - INFO - Final model saved to logs/drqn_mdp/drqn_mdp_final.pt
2025-12-01 15:10:11,363 - INFO - Evaluation checkpoint saved to logs/drqn_mdp/model.pt
2025-12-01 15:10:11,363 - INFO - ==================================================
2025-12-01 15:10:11,363 - INFO - EXPERIMENT SUMMARY
2025-12-01 15:10:11,363 - INFO - ==================================================
2025-12-01 15:10:11,363 - INFO - Model: drqn
2025-12-01 15:10:11,363 - INFO - Environment: mdp
2025-12-01 15:10:11,363 - INFO - Training Episodes: 500
2025-12-01 15:10:11,363 - INFO - Final Avg Reward: 0.460
2025-12-01 15:10:11,363 - INFO - Success Rate: 0.280
2025-12-01 15:10:11,363 - INFO - Training Time: 34.20s
2025-12-01 15:10:11,363 - INFO - ==================================================
