2025-09-12 10:04:57,598 - INFO - Starting experiment: drqn_test
2025-09-12 10:04:57,598 - INFO - Model: drqn, Environment: mdp
2025-09-12 10:04:57,598 - INFO - Model config: DRQNConfig(hidden_size=32, num_layers=2, learning_rate=0.001, batch_size=32, epsilon=0.2, gamma=0.98, buffer_capacity=8192, target_update_freq=10, cell_type='gru')
2025-09-12 10:04:57,598 - INFO - Environment config: MDPConfig(name='mdp', s1_duration=3, s2_duration=3)
2025-09-12 10:04:57,598 - INFO - Training config: TrainingConfig(num_episodes=5, eval_period=100, num_rollouts=50, save_period=1000, log_dir='./logs', save_dir='./models', seed=42, cuda=False)
2025-09-12 10:04:57,598 - INFO - Using CPU
2025-09-12 10:04:57,598 - INFO - Created environment: MDPEnvironment
2025-09-12 10:04:58,147 - INFO - Created agent: DRQNAgent
2025-09-12 10:04:58,148 - INFO - Starting DRQN training on Two-Step task
2025-09-12 10:04:58,152 - INFO - Training completed in 0.00 seconds
2025-09-12 10:04:58,152 - INFO - Evaluating agent for 50 rollouts
2025-09-12 10:04:58,155 - INFO - Evaluation Results - Avg Reward: 0.560, Success Rate: 0.560
2025-09-12 10:04:58,157 - INFO - Model saved to ./models/drqn_test.pt
2025-09-12 10:04:58,157 - INFO - ==================================================
2025-09-12 10:04:58,157 - INFO - EXPERIMENT SUMMARY
2025-09-12 10:04:58,157 - INFO - ==================================================
2025-09-12 10:04:58,157 - INFO - Model: drqn
2025-09-12 10:04:58,157 - INFO - Environment: mdp
2025-09-12 10:04:58,157 - INFO - Training Episodes: 5
2025-09-12 10:04:58,157 - INFO - Final Avg Reward: 0.560
2025-09-12 10:04:58,157 - INFO - Success Rate: 0.560
2025-09-12 10:04:58,157 - INFO - Training Time: 0.00s
2025-09-12 10:04:58,158 - INFO - ==================================================
